{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_xpW8ebJBEM",
        "outputId": "60d51a2e-e350-40e5-f239-80b9a2a8f99f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTcbb_NTJUJp"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"reddit-comments-2015-08.csv\")\n",
        "data = data[:500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGDOp9lHN0vo"
      },
      "outputs": [],
      "source": [
        "data = list(data.body)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pScLXkY_Lyup"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "for i,j in enumerate(data):\n",
        "    data[i] = j.strip()\n",
        "    data[i] = j.split(\".\")\n",
        "data = [j for sub in data for j in sub]\n",
        "data = [i.split(\" \") for i in data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jJAMbBZMHEx"
      },
      "outputs": [],
      "source": [
        "wnl = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "for i,j in enumerate(data):\n",
        "    data[i] = [i.lower() for i in j]\n",
        "    data[i] = [i for i in j if i not in stop_words]\n",
        "    data[i] = [''.join(c for c in s if c not in string.punctuation) for s in data[i]]\n",
        "    data[i] = [wnl.lemmatize(k) for k in data[i]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-sJ9SfWMIqg"
      },
      "outputs": [],
      "source": [
        "unique_words = set()\n",
        "for i in data:\n",
        "    for j in i:\n",
        "        unique_words.add(j)\n",
        "unique_words = list(unique_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPDfzQnPYlxT"
      },
      "outputs": [],
      "source": [
        "# one hot encoding\n",
        "one_hot = []\n",
        "for i in data:\n",
        "    words = []\n",
        "    for k in i:\n",
        "        temp = [0]*len(unique_words)\n",
        "        for j in range(len(unique_words)):\n",
        "            if k == unique_words[j]:\n",
        "                temp[j] = 1\n",
        "                break\n",
        "        words.append(temp)\n",
        "    one_hot.append(words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# split data into train and test\n",
        "train_data = one_hot[:int(len(one_hot) * 0.8)]\n",
        "test_data = one_hot[int(len(one_hot) * 0.8):]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write a class for RNN from scratch\n",
        "\n",
        "class RNN:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        self.Wxh = np.random.randn(hidden_size, input_size) * 0.01\n",
        "        self.Whh = np.random.randn(hidden_size, hidden_size) * 0.01\n",
        "        self.Why = np.random.randn(output_size, hidden_size) * 0.01\n",
        "        \n",
        "        self.bh = np.zeros((hidden_size, 1))\n",
        "        self.by = np.zeros((output_size, 1))\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        hs = {}\n",
        "        ys = {}\n",
        "        hs[-1] = np.zeros((self.hidden_size, 1))\n",
        "        for t in range(len(inputs)):\n",
        "            hs[t] = np.tanh(np.dot(self.Wxh, inputs[t]) + np.dot(self.Whh, hs[t-1]) + self.bh)\n",
        "            ys[t] = np.dot(self.Why, hs[t]) + self.by\n",
        "        return hs, ys\n",
        "\n",
        "    def backward(self, inputs, hs, ys, targets):\n",
        "        dWxh = np.zeros_like(self.Wxh)\n",
        "        dWhh = np.zeros_like(self.Whh)\n",
        "        dWhy = np.zeros_like(self.Why)\n",
        "        \n",
        "        dbh = np.zeros_like(self.bh)\n",
        "        dby = np.zeros_like(self.by)\n",
        "        \n",
        "        dhnext = np.zeros_like(hs[0])\n",
        "        \n",
        "        for t in reversed(range(len(inputs))):\n",
        "            dy = np.copy(ys[t])\n",
        "            dWhy += np.dot(dy, hs[t].T)\n",
        "            dby += dy\n",
        "            \n",
        "            dh = np.dot(self.Why.T, dy) + dhnext\n",
        "            dhraw = (1 - hs[t] * hs[t]) * dh\n",
        "            dbh += dhraw\n",
        "            \n",
        "            dWxh += np.dot(dhraw, inputs[t].T)\n",
        "            dWhh += np.dot(dhraw, hs[t-1].T)\n",
        "            dhnext = np.dot(self.Whh.T, dhraw)\n",
        "            \n",
        "        for dparam in [dWxh, dWhh, dWhy, dbh, dby]:\n",
        "            np.clip(dparam, -5, 5, out=dparam)\n",
        "            \n",
        "        return dWxh, dWhh, dWhy, dbh, dby\n",
        "\n",
        "    def train(self, inputs, targets, learning_rate):\n",
        "        hs, ys = self.forward(inputs)\n",
        "        dWxh, dWhh, dWhy, dbh, dby = self.backward(inputs, hs, ys, targets)\n",
        "        \n",
        "        for param, dparam in zip([self.Wxh, self.Whh, self.Why, self.bh, self.by],\n",
        "                                [dWxh, dWhh, dWhy, dbh, dby]):\n",
        "            param += -learning_rate * dparam\n",
        "        return hs[len(inputs)-1], ys[len(inputs)-1]\n",
        "    \n",
        "    def predict(self, inputs):\n",
        "        hs, ys = self.forward(inputs)\n",
        "        return ys[len(inputs)-1]\n",
        "    \n",
        "    def loss(self, inputs, targets):\n",
        "        loss = 0\n",
        "        for i in range(len(inputs)):\n",
        "            hs, ys = self.forward(inputs[i])\n",
        "            loss += -np.log(ys[len(inputs[i])-1][targets[i]])\n",
        "        return loss/len(inputs)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model\n",
        "rnn = RNN(len(unique_words), 100, len(unique_words))\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "for epoch in range(epochs):\n",
        "    for i in range(len(train_data)):\n",
        "        inputs = train_data[i]\n",
        "        targets = [unique_words.index(j) for j in data[i][1:]]\n",
        "        rnn.train(inputs, targets, learning_rate)\n",
        "    print(\"Epoch: \", epoch, \" Loss: \", rnn.loss(train_data, targets))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
