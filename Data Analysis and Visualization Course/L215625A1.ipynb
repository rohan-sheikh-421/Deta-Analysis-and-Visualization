{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1 Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import re\n",
    "import openpyxl\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_path='C:\\\\Users\\\\Lenovo\\\\OneDrive\\\\Documents\\\\chromedriver.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "#All are optional\n",
    "options.add_experimental_option(\"detach\", True)\n",
    "options.add_argument(\"--disable-extensions\")\n",
    "options.add_argument(\"--disable-notifications\")\n",
    "options.add_argument(\"--disable-Advertisement\")\n",
    "options.add_argument(\"--disable-popup-blocking\")\n",
    "options.add_argument(\"start-maximized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Service(driver_path)\n",
    "driver = webdriver.Chrome(options=options,service=service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_path=\"https://www.youtube.com/@UnfoldDataScience/videos\"\n",
    "driver.get(url_path)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = []\n",
    "SCROLL_PAUSE = 1\n",
    "last_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "\n",
    "count = 170\n",
    "\n",
    "while count > len(item):\n",
    "    driver.execute_script(\"window.scrollTo(0,document.documentElement.scrollHeight);\")\n",
    "    time.sleep(SCROLL_PAUSE)\n",
    "    new_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n",
    "\n",
    "\n",
    "data = []\n",
    "try:\n",
    "    for e in WebDriverWait(driver, 20).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div#details'))):\n",
    "    \n",
    "        vurl = e.find_element(By.CSS_SELECTOR,'a#video-title-link').get_attribute('href')\n",
    "        data.append(vurl)\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "411"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments=[]\n",
    "likes_count=[]\n",
    "title=[]\n",
    "views=[]\n",
    "upload_date=[]\n",
    "for i in range(0,10):\n",
    "    driver.get(data[i])\n",
    "    time.sleep(7)\n",
    "    likes_count.append(driver.find_element(By.XPATH,'.//*[@id=\"segmented-like-button\"]/ytd-toggle-button-renderer/yt-button-shape/button/div[2]').text)\n",
    "    title.append(driver.find_element(By.CLASS_NAME,'style-scope ytd-watch-metadata').text)\n",
    "    more_button = driver.find_element(By.CSS_SELECTOR,'#expand')\n",
    "    more_button.click()\n",
    "    views.append(driver.find_element(By.XPATH,'.//*[@id=\"info\"]/span[1]').text)\n",
    "    upload_date.append(driver.find_element(By.XPATH,'.//*[@id=\"info\"]/span[3]').text)\n",
    "    driver.execute_script(\"return scrollBy(0,6000);\")\n",
    "    time.sleep(7)\n",
    "    comments.append(WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH,\"//h2[@id='count']/yt-formatted-string\"))).text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_title(data):\n",
    "  new_data = []\n",
    "  for string in data:\n",
    "    new_data.append(string[:string.find(\"|\")].strip())\n",
    "  return new_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=extract_title(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_int_value(comments):\n",
    "  int_values = []\n",
    "  for comment in comments:\n",
    "    comment = re.sub(r\"[^\\d\\-+\\.]\", \"\", comment)\n",
    "    int_value = float(comment)\n",
    "    int_values.append(int_value)\n",
    "\n",
    "  return int_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_=extract_int_value(comments)\n",
    "views_=extract_int_value(views)\n",
    "likes_=extract_int_value(likes_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={'Title':titles,\n",
    "      'Views':views_,\n",
    "      'Likes':likes_,\n",
    "      'Comments':comments_,\n",
    "      'Date':upload_date}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Views</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simplifying Confidence Intervals</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Sep 14, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cost of Living in London</td>\n",
       "      <td>1623.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Sep 6, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6 Activation functions for deep learning</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Sep 3, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 python packages to wow your client</td>\n",
       "      <td>1593.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Aug 24, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Junior data scientist to Senior Data Scientist</td>\n",
       "      <td>1330.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Aug 21, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Encode decoder seq 2 seq architecture</td>\n",
       "      <td>1452.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Aug 17, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Participate and learn more</td>\n",
       "      <td>760.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Aug 10, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How to Pass AWS ML specialty exam</td>\n",
       "      <td>3570.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Aug 3, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LSTM next word prediction in Python</td>\n",
       "      <td>2314.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Jul 24, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LSTM explained simply</td>\n",
       "      <td>4704.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Jul 19, 2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Title   Views  Likes  Comments  \\\n",
       "0                Simplifying Confidence Intervals  1083.0   41.0      11.0   \n",
       "1                        Cost of Living in London  1623.0   56.0      15.0   \n",
       "2        6 Activation functions for deep learning  1262.0   46.0      10.0   \n",
       "3            5 python packages to wow your client  1593.0   75.0      11.0   \n",
       "4  Junior data scientist to Senior Data Scientist  1330.0   61.0      16.0   \n",
       "5           Encode decoder seq 2 seq architecture  1452.0   54.0       5.0   \n",
       "6                      Participate and learn more   760.0   32.0      14.0   \n",
       "7               How to Pass AWS ML specialty exam  3570.0  137.0       6.0   \n",
       "8             LSTM next word prediction in Python  2314.0   88.0      15.0   \n",
       "9                           LSTM explained simply  4704.0  195.0      38.0   \n",
       "\n",
       "           Date  \n",
       "0  Sep 14, 2023  \n",
       "1   Sep 6, 2023  \n",
       "2   Sep 3, 2023  \n",
       "3  Aug 24, 2023  \n",
       "4  Aug 21, 2023  \n",
       "5  Aug 17, 2023  \n",
       "6  Aug 10, 2023  \n",
       "7   Aug 3, 2023  \n",
       "8  Jul 24, 2023  \n",
       "9  Jul 19, 2023  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe=pd.DataFrame(data)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv('extracted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Views</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Simplifying Confidence Intervals</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Sep 14, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cost of Living in London</td>\n",
       "      <td>1623.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Sep 6, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6 Activation functions for deep learning</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Sep 3, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5 python packages to wow your client</td>\n",
       "      <td>1593.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Aug 24, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Junior data scientist to Senior Data Scientist</td>\n",
       "      <td>1330.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Aug 21, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Encode decoder seq 2 seq architecture</td>\n",
       "      <td>1452.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Aug 17, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Participate and learn more</td>\n",
       "      <td>760.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Aug 10, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>How to Pass AWS ML specialty exam</td>\n",
       "      <td>3570.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Aug 3, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>LSTM next word prediction in Python</td>\n",
       "      <td>2314.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Jul 24, 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>LSTM explained simply</td>\n",
       "      <td>4704.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Jul 19, 2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           Title   Views  Likes  \\\n",
       "0           0                Simplifying Confidence Intervals  1083.0   41.0   \n",
       "1           1                        Cost of Living in London  1623.0   56.0   \n",
       "2           2        6 Activation functions for deep learning  1262.0   46.0   \n",
       "3           3            5 python packages to wow your client  1593.0   75.0   \n",
       "4           4  Junior data scientist to Senior Data Scientist  1330.0   61.0   \n",
       "5           5           Encode decoder seq 2 seq architecture  1452.0   54.0   \n",
       "6           6                      Participate and learn more   760.0   32.0   \n",
       "7           7               How to Pass AWS ML specialty exam  3570.0  137.0   \n",
       "8           8             LSTM next word prediction in Python  2314.0   88.0   \n",
       "9           9                           LSTM explained simply  4704.0  195.0   \n",
       "\n",
       "   Comments          Date  \n",
       "0      11.0  Sep 14, 2023  \n",
       "1      15.0   Sep 6, 2023  \n",
       "2      10.0   Sep 3, 2023  \n",
       "3      11.0  Aug 24, 2023  \n",
       "4      16.0  Aug 21, 2023  \n",
       "5       5.0  Aug 17, 2023  \n",
       "6      14.0  Aug 10, 2023  \n",
       "7       6.0   Aug 3, 2023  \n",
       "8      15.0  Jul 24, 2023  \n",
       "9      38.0  Jul 19, 2023  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg=pd.read_csv('extracted.csv')\n",
    "\n",
    "dg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg['Date'] = pd.to_datetime(dg['Date'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1390.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def avg_views(d1, d2):\n",
    "\n",
    "  avg_views_df = dg.loc[(dg['Date'] > '2023-08-15')]\n",
    "\n",
    "  total_views = avg_views_df['Views'].sum()\n",
    "\n",
    "  num_videos = avg_views_df.shape[0]\n",
    "  avg_views = total_views / num_videos\n",
    "\n",
    "  return avg_views\n",
    "\n",
    "print(avg_views(dg['Views'], dg['Date']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Activation functions for deep learning\n"
     ]
    }
   ],
   "source": [
    "#Identify the video with the highest likes-to-views ratio.\n",
    "def highest_ratio(data):  \n",
    "    for i in range(1,len(data)):\n",
    "         if data['Likes'][i]/data['Views'][i]>data['Likes'][i-1]/data['Views'][i-1]:\n",
    "            return data['Title'][i]\n",
    "print(highest_ratio(dg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6562831137481018\n"
     ]
    }
   ],
   "source": [
    "#Find the correlation between the number of likes and the number of comments for the videos.\n",
    "corr=dg['Likes'].corr(dg['Comments'])\n",
    "print(corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thursday'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the most common day of the week for video uploads.\n",
    "dg['Day'] = dg['Date'].dt.day_name()\n",
    "dg['Day'].value_counts().idxmax()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Views</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Date</th>\n",
       "      <th>Day</th>\n",
       "      <th>z_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, Title, Views, Likes, Comments, Date, Day, z_score]\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Detect any outliers in the views count.\n",
    "dg['z_score'] = (dg['Views'] - dg['Views'].mean())/dg['Views'].std()\n",
    "dg.loc[dg['z_score'] > 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1 Part 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests) (1.26.6)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.2.post1)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n",
    "!pip install beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_path=[\"https://www.imdb.com/search/title/?title_type=feature&year=2013,2023&sort=num_votes,desc\",\n",
    "     \"https://www.imdb.com/search/title/?title_type=feature&year=2013-01-01,2023-12-31&sort=num_votes,desc&start=51&ref_=adv_nxt\",\n",
    "     \"https://www.imdb.com/search/title/?title_type=feature&year=2013-01-01,2023-12-31&sort=num_votes,desc&start=101&ref_=adv_nxt\",\n",
    "     \"https://www.imdb.com/search/title/?title_type=feature&year=2013-01-01,2023-12-31&sort=num_votes,desc&start=151&ref_=adv_nxt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies=[]\n",
    "ratings=[]\n",
    "for i in url_path:\n",
    "    response=requests.get(i)\n",
    "    soup=BeautifulSoup(response.content,'html.parser')\n",
    "    result=soup.find(class_=\"lister-list\")\n",
    "    movie_element=result.find_all(class_=\"lister-item mode-advanced\")\n",
    "    for m_e in movie_element:\n",
    "        title=m_e.find(class_=\"lister-item-header\").find('a').get_text()\n",
    "        year=int(m_e.find(\"span\",class_=\"lister-item-year text-muted unbold\").get_text().replace('(','').replace(')','').replace('I','').replace(' ','').replace('V','').replace('X',''))\n",
    "        director=m_e.find(\"p\",class_=\"\").find('a').get_text()\n",
    "        genre=m_e.find(\"span\",class_=\"genre\").get_text().replace('\\n','').replace(' ','')\n",
    "      \n",
    "      \n",
    "        movies.append({\n",
    "            \"Title\": title,\n",
    "            \"Release_year\":year,\n",
    "            \"Director\": director,\n",
    "            \"Genre\": genre\n",
    "        })\n",
    "    rating=soup.find_all(\"div\",class_=\"inline-block ratings-imdb-rating\")\n",
    "    for r in rating:\n",
    "        ratings.append(float(r.find('strong').get_text()))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Rating']=ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.260714285714284\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "avg_rating=df[df['Rating']>8.0]['Rating'].mean()\n",
    "print(avg_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biography,Drama,History\n"
     ]
    }
   ],
   "source": [
    "#The most common genre among the top-rated movies.\n",
    "common_genre=df[df['Rating']>8.0]['Genre'].value_counts().idxmax()\n",
    "print(common_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Director\n",
      "Vivek Agnihotri    8.6\n",
      "Name: Rating, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Identify the director with the highest average IMDb rating.\n",
    "director_rating=df.groupby('Director')['Rating'].mean().sort_values(ascending=False).head(1)\n",
    "print(director_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    }
   ],
   "source": [
    "#Determine the year with the highest number of top-rated movies.\n",
    "year_rating=df[df['Rating']>8.0]['Release_year'].value_counts().idxmax()\n",
    "print(year_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n",
      "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
      "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
      "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
      "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
      "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
      "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
      "\n",
      "        b  lstat  medv  \n",
      "0  396.90   4.98  24.0  \n",
      "1  396.90   9.14  21.6  \n",
      "2  392.83   4.03  34.7  \n",
      "3  394.63   2.94  33.4  \n",
      "4  396.90   5.33  36.2  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('C:\\\\Users\\\\Lenovo\\\\OneDrive\\\\Documents\\\\house.csv')\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretize the \"age\" variable into three bins\n",
    "age_bins = [0, 25, 50, float('inf')]\n",
    "age_labels = ['Young', 'Middle-aged', 'Old']\n",
    "data['age_group'] = pd.cut(data['age'], bins=age_bins, labels=age_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['is_charles_river'] = data['chas'].apply(lambda x: 'Yes' if x == 1 else 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove outliers using IQR\n",
    "def remove_outliers(column):\n",
    "    Q1 = column.quantile(0.25)\n",
    "    Q3 = column.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return column[(column >= lower_bound) & (column <= upper_bound)]\n",
    "\n",
    "# Remove outliers for each numerical column in the dataset\n",
    "numerical_columns = ['crim', 'zn', 'indus', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'b', 'lstat', 'medv']\n",
    "for col in numerical_columns:\n",
    "    data[col] = remove_outliers(data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "window_size = 3\n",
    "data['rm_smoothed'] = data['rm'].rolling(window=window_size, min_periods=1).mean()\n",
    "\n",
    "data['tax_normalized'] = (data['tax'] - data['tax'].min()) / (data['tax'].max() - data['tax'].min())\n",
    "data['lstat_normalized'] = (data['lstat'] - data['lstat'].min()) / (data['lstat'].max() - data['lstat'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear Regression Model Coefficients:\n",
      "Coefficient (slope): 9.102108981180308\n",
      "Intercept: -34.670620776438554\n"
     ]
    }
   ],
   "source": [
    "# Perform a simple linear regression to predict the median value of \"medv\" based on \"rm\"\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = data[['rm']]\n",
    "y = data['medv']\n",
    "\n",
    "# Create and fit the regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Print the coefficients and intercept of the regression model\n",
    "print(\"\\nLinear Regression Model Coefficients:\")\n",
    "print(f\"Coefficient (slope): {model.coef_[0]}\")\n",
    "print(f\"Intercept: {model.intercept_}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Replace missing values with the mean of the column\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = imputer.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset=['rm'], inplace=True)  # Removes rows with missing 'rm' values\n",
    "X = data[['rm']]\n",
    "y = data['medv']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
